---
title: "Solving Schrödinger Equation with a Language Model"
author: "Shang, Honghui; Guo, Chu; Wu, Yangjun; Li, Zhenyu; Yang, Jinlong"
collection: publications
category: 2023
permalink: /publication/2023-07-18-Solving-Schrödinger-Equation-with-a-Language-Model
date: 2023-07-18
paperurl: 'https://doi.org/10.48550/arXiv.2307.09343'
---

The fundamental many-electron Schrödinger equation is solved straightforwardly with QiankunNet, a neural network quantum state (NNQS) framework based on generative Transformer architecture along with a batched autoregressive sampling method tailored for this Transformer-based ansatz in quantum chemistry calculations. This approach significantly improves the accuracy and efficiency of first-principles calculations compared to previous fermionic ansatz methods. The intricate quantum correlations are effectively captured by incorporating an attention mechanism into the methodology. Additionally, a batched autoregressive sampling strategy is employed to substantially enhance the sampling accuracy and efficiency. Furthermore, QiankunNet can incorporate a pre-training stage, where the truncated configuration interaction solution is embedded into the variational ansatz, ensuring high expressiveness and further boosting computational efficiency. QiankunNet showcases the power of the Transformer-based language model in achieving unprecedented efficiency in quantum chemistry calculations, opening up new avenues for chemical discovery and demonstrating the potential to solve the large-scale Schrödinger equation with modest computational cost. © 2023, CC BY.
